{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, sys, time, random, itertools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Lambda, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# debugging logs\n",
    "# 0 = all messages are logged (default behavior)\n",
    "# 1 = INFO messages are not printed\n",
    "# 2 = INFO and WARNING messages are not printed\n",
    "# 3 = INFO, WARNING, and ERROR messages are not printed\n",
    "# this should be placed before importing tensorflow\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "# enable GPU device\n",
    "#os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'\n",
    "#os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "\n",
    "# reproducibility\n",
    "seed = 1234567\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1,inter_op_parallelism_threads=1)\n",
    "sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(),config=session_conf)\n",
    "tf.compat.v1.keras.backend.set_session(sess)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def read_data_sets():\n",
    "    # load MSD dataset\n",
    "    data = pd.read_csv('./YearPredictionMSD2.csv')\n",
    "\n",
    "    # plot histogram\n",
    "    if 0:\n",
    "        data = data.rename(index=str, columns={'label':'year'})\n",
    "        nsongs = {}\n",
    "        for y in range(1922, 2012):\n",
    "            nsongs[y] = len(data[data.year == y])\n",
    "        yrs = range(1922, 2011)\n",
    "        values = [nsongs[y] for y in yrs]\n",
    "        plt.bar(yrs, values, align='center')\n",
    "        plt.xlabel('Year')\n",
    "        plt.ylabel('Number of songs')\n",
    "        plt.show()\n",
    "\n",
    "    # scale the data sets to the interval [0,1]\n",
    "    X = data.iloc[:,1:].to_numpy()\n",
    "    Y = data.iloc[:,0].to_numpy()\n",
    "    a, b = X.min(), X.max()\n",
    "    X = (X - a) / (b - a)\n",
    "    Y = Y - Y.min()  # 1922-2011 are mapped to 0-89\n",
    "\n",
    "    # shuffle the dataset\n",
    "    nb_samples = X.shape[0]\n",
    "    ind = np.random.permutation(nb_samples)\n",
    "    X, Y = X[ind,:], Y[ind]\n",
    "\n",
    "    # split data sets\n",
    "    x_train, y_train = X[:463715,:], Y[:463715]\n",
    "    x_test, y_test = X[463715:,:], Y[463715:]\n",
    "    return x_train, y_train, x_test, y_test"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "    # set parameters\n",
    "nb_classes = 90\n",
    "epochs = 10\n",
    "batch_size = 64\n",
    "\n",
    "    # 1) load MSD dataset\n",
    "x_train, y_train_t, x_test, y_test_t = read_data_sets()\n",
    "\n",
    "    # 2a) standardize features by removing the mean and scaling to unit variance\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(x_train)\n",
    "X_train_std = scaler.transform(x_train)\n",
    "X_test_std = scaler.transform(x_test)\n",
    "\n",
    "    # 2b) run principal component analysis (PCA)\n",
    "pca = PCA(n_components=0.9)\n",
    "pca.fit(X_train_std)\n",
    "X_train_proc = pca.transform(X_train_std)\n",
    "X_test_proc = pca.transform(X_test_std)\n",
    "\n",
    "    # 2c) encode labels to one-hot coding\n",
    "y_train = to_categorical(y_train_t, nb_classes)\n",
    "y_test = to_categorical(y_test_t, nb_classes)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "   # 3) build a model\n",
    "if 1:\n",
    "    model = Sequential()\n",
    "    model.add(Dense(55, input_shape=(55,)))\n",
    "    model.add(Dense(110))\n",
    "    model.add(Dense(nb_classes, activation='softmax'))\n",
    "else:\n",
    "    model = Sequential()\n",
    "    model.add(Dense(180, input_shape=(55,)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(360, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(360, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(nb_classes, activation='softmax'))\n",
    "\n",
    "    # 4) compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # 5) train the model\n",
    "lr_schedule = ReduceLROnPlateau(monitor='val_loss', patience=2, verbose=1, factor=0.5, min_lr=0.0001)\n",
    "hist = model.fit(X_train_proc, y_train, validation_data=(X_test_proc, y_test),\n",
    "                epochs=epochs, batch_size=batch_size, callbacks=[lr_schedule])\n",
    "\n",
    "    # 6) evaluate model's performance\n",
    "pred = model.predict(X_test_proc)  # (51630, 55)\n",
    "pred_class = np.argmax(pred, axis=-1)  # (51630,)\n",
    "print('Mean Absolute Error: %f' % np.mean(np.absolute(y_test_t - pred_class)))\n",
    "print('Mean Square Error: %f' % np.sqrt(np.mean(np.absolute(y_test_t - pred_class)^2)))\n",
    "\n",
    "    # model_1: Mean Absolute Error: 8.411118, Mean Square Error: 2.928557\n",
    "    # model_2: Mean Absolute Error: 7.303564, Mean Square Error: 2.738096\n",
    "\n",
    "elapsed = time.time() - start\n",
    "print('Elapsed {:.2f} minutes'.format(elapsed/60.0))\n",
    "return 0"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
