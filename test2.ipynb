{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets, svm, metrics\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import preprocessing\n",
    "from sklearn.utils import resample\n",
    "import itertools\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.manifold import TSNE\n",
    "%matplotlib inline\n",
    "import pandas as pd"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "       Unnamed: 0  label  TimbreAvg1  TimbreAvg2  TimbreAvg3  TimbreAvg4   \n4187       260471   1990    0.664071    0.408507    0.526585    0.320343  \\\n18167       41467   2010    0.680000    0.396398    0.483676    0.287004   \n9085       226737   1980    0.692805    0.539383    0.489375    0.300020   \n14637      210451   1960    0.739219    0.458705    0.533999    0.331135   \n7053        63933   1980    0.585070    0.453026    0.527596    0.283752   \n\n       TimbreAvg5  TimbreAvg6  TimbreAvg7  TimbreAvg8  ...   \n4187     0.404907    0.292975    0.534659    0.320515  ...  \\\n18167    0.378026    0.259346    0.543910    0.350303  ...   \n9085     0.376677    0.267675    0.507225    0.401283  ...   \n14637    0.405547    0.337043    0.516093    0.330416  ...   \n7053     0.419308    0.262895    0.444359    0.325797  ...   \n\n       TimbreCovariance69  TimbreCovariance70  TimbreCovariance71   \n4187             0.367590            0.484869            0.361385  \\\n18167            0.344713            0.476929            0.358765   \n9085             0.336665            0.494891            0.356429   \n14637            0.337260            0.485689            0.366679   \n7053             0.372406            0.488001            0.369975   \n\n       TimbreCovariance72  TimbreCovariance73  TimbreCovariance74   \n4187             0.644992            0.549720            0.468457  \\\n18167            0.636166            0.567708            0.469957   \n9085             0.637543            0.554899            0.460975   \n14637            0.646995            0.588726            0.444633   \n7053             0.652277            0.587300            0.460090   \n\n       TimbreCovariance75  TimbreCovariance76  TimbreCovariance77   \n4187             0.600904            0.328646            0.502387  \\\n18167            0.568867            0.331960            0.517613   \n9085             0.574456            0.332778            0.505202   \n14637            0.602343            0.337146            0.490925   \n7053             0.625541            0.323246            0.504353   \n\n       TimbreCovariance78  \n4187             0.374182  \n18167            0.342542  \n9085             0.365124  \n14637            0.360085  \n7053             0.360849  \n\n[5 rows x 92 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>label</th>\n      <th>TimbreAvg1</th>\n      <th>TimbreAvg2</th>\n      <th>TimbreAvg3</th>\n      <th>TimbreAvg4</th>\n      <th>TimbreAvg5</th>\n      <th>TimbreAvg6</th>\n      <th>TimbreAvg7</th>\n      <th>TimbreAvg8</th>\n      <th>...</th>\n      <th>TimbreCovariance69</th>\n      <th>TimbreCovariance70</th>\n      <th>TimbreCovariance71</th>\n      <th>TimbreCovariance72</th>\n      <th>TimbreCovariance73</th>\n      <th>TimbreCovariance74</th>\n      <th>TimbreCovariance75</th>\n      <th>TimbreCovariance76</th>\n      <th>TimbreCovariance77</th>\n      <th>TimbreCovariance78</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>4187</th>\n      <td>260471</td>\n      <td>1990</td>\n      <td>0.664071</td>\n      <td>0.408507</td>\n      <td>0.526585</td>\n      <td>0.320343</td>\n      <td>0.404907</td>\n      <td>0.292975</td>\n      <td>0.534659</td>\n      <td>0.320515</td>\n      <td>...</td>\n      <td>0.367590</td>\n      <td>0.484869</td>\n      <td>0.361385</td>\n      <td>0.644992</td>\n      <td>0.549720</td>\n      <td>0.468457</td>\n      <td>0.600904</td>\n      <td>0.328646</td>\n      <td>0.502387</td>\n      <td>0.374182</td>\n    </tr>\n    <tr>\n      <th>18167</th>\n      <td>41467</td>\n      <td>2010</td>\n      <td>0.680000</td>\n      <td>0.396398</td>\n      <td>0.483676</td>\n      <td>0.287004</td>\n      <td>0.378026</td>\n      <td>0.259346</td>\n      <td>0.543910</td>\n      <td>0.350303</td>\n      <td>...</td>\n      <td>0.344713</td>\n      <td>0.476929</td>\n      <td>0.358765</td>\n      <td>0.636166</td>\n      <td>0.567708</td>\n      <td>0.469957</td>\n      <td>0.568867</td>\n      <td>0.331960</td>\n      <td>0.517613</td>\n      <td>0.342542</td>\n    </tr>\n    <tr>\n      <th>9085</th>\n      <td>226737</td>\n      <td>1980</td>\n      <td>0.692805</td>\n      <td>0.539383</td>\n      <td>0.489375</td>\n      <td>0.300020</td>\n      <td>0.376677</td>\n      <td>0.267675</td>\n      <td>0.507225</td>\n      <td>0.401283</td>\n      <td>...</td>\n      <td>0.336665</td>\n      <td>0.494891</td>\n      <td>0.356429</td>\n      <td>0.637543</td>\n      <td>0.554899</td>\n      <td>0.460975</td>\n      <td>0.574456</td>\n      <td>0.332778</td>\n      <td>0.505202</td>\n      <td>0.365124</td>\n    </tr>\n    <tr>\n      <th>14637</th>\n      <td>210451</td>\n      <td>1960</td>\n      <td>0.739219</td>\n      <td>0.458705</td>\n      <td>0.533999</td>\n      <td>0.331135</td>\n      <td>0.405547</td>\n      <td>0.337043</td>\n      <td>0.516093</td>\n      <td>0.330416</td>\n      <td>...</td>\n      <td>0.337260</td>\n      <td>0.485689</td>\n      <td>0.366679</td>\n      <td>0.646995</td>\n      <td>0.588726</td>\n      <td>0.444633</td>\n      <td>0.602343</td>\n      <td>0.337146</td>\n      <td>0.490925</td>\n      <td>0.360085</td>\n    </tr>\n    <tr>\n      <th>7053</th>\n      <td>63933</td>\n      <td>1980</td>\n      <td>0.585070</td>\n      <td>0.453026</td>\n      <td>0.527596</td>\n      <td>0.283752</td>\n      <td>0.419308</td>\n      <td>0.262895</td>\n      <td>0.444359</td>\n      <td>0.325797</td>\n      <td>...</td>\n      <td>0.372406</td>\n      <td>0.488001</td>\n      <td>0.369975</td>\n      <td>0.652277</td>\n      <td>0.587300</td>\n      <td>0.460090</td>\n      <td>0.625541</td>\n      <td>0.323246</td>\n      <td>0.504353</td>\n      <td>0.360849</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 92 columns</p>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('msd_sampled.csv')\n",
    "df.sample(5)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "       label  TimbreAvg1  TimbreAvg2  TimbreAvg3  TimbreAvg4  TimbreAvg5   \n17595   2010    0.715262    0.521391    0.497942    0.310532    0.330921  \\\n18409   2010    0.850959    0.497077    0.513089    0.309858    0.416551   \n18387   2010    0.744080    0.565185    0.468783    0.371875    0.408303   \n874     2000    0.781150    0.517066    0.447713    0.357330    0.383889   \n20128   1950    0.742257    0.464650    0.604671    0.335042    0.255843   \n\n       TimbreAvg6  TimbreAvg7  TimbreAvg8  TimbreAvg9  ...   \n17595    0.297091    0.538107    0.420134    0.479281  ...  \\\n18409    0.252103    0.520007    0.397299    0.462120  ...   \n18387    0.373937    0.542301    0.381735    0.452571  ...   \n874      0.243170    0.542672    0.429323    0.482315  ...   \n20128    0.378839    0.405812    0.350103    0.532451  ...   \n\n       TimbreCovariance69  TimbreCovariance70  TimbreCovariance71   \n17595            0.335328            0.489459            0.372010  \\\n18409            0.349319            0.480013            0.367315   \n18387            0.329568            0.490258            0.389173   \n874              0.340546            0.495296            0.352396   \n20128            0.356147            0.481544            0.376804   \n\n       TimbreCovariance72  TimbreCovariance73  TimbreCovariance74   \n17595            0.666589            0.576244            0.476087  \\\n18409            0.654323            0.583672            0.462159   \n18387            0.642056            0.574659            0.492379   \n874              0.626926            0.571545            0.454724   \n20128            0.660790            0.568658            0.460765   \n\n       TimbreCovariance75  TimbreCovariance76  TimbreCovariance77   \n17595            0.585789            0.339055            0.507992  \\\n18409            0.597104            0.350401            0.499580   \n18387            0.629543            0.365311            0.498886   \n874              0.585541            0.344452            0.506372   \n20128            0.635322            0.367661            0.507381   \n\n       TimbreCovariance78  \n17595            0.294227  \n18409            0.368927  \n18387            0.360283  \n874              0.364665  \n20128            0.387547  \n\n[5 rows x 91 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>TimbreAvg1</th>\n      <th>TimbreAvg2</th>\n      <th>TimbreAvg3</th>\n      <th>TimbreAvg4</th>\n      <th>TimbreAvg5</th>\n      <th>TimbreAvg6</th>\n      <th>TimbreAvg7</th>\n      <th>TimbreAvg8</th>\n      <th>TimbreAvg9</th>\n      <th>...</th>\n      <th>TimbreCovariance69</th>\n      <th>TimbreCovariance70</th>\n      <th>TimbreCovariance71</th>\n      <th>TimbreCovariance72</th>\n      <th>TimbreCovariance73</th>\n      <th>TimbreCovariance74</th>\n      <th>TimbreCovariance75</th>\n      <th>TimbreCovariance76</th>\n      <th>TimbreCovariance77</th>\n      <th>TimbreCovariance78</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>17595</th>\n      <td>2010</td>\n      <td>0.715262</td>\n      <td>0.521391</td>\n      <td>0.497942</td>\n      <td>0.310532</td>\n      <td>0.330921</td>\n      <td>0.297091</td>\n      <td>0.538107</td>\n      <td>0.420134</td>\n      <td>0.479281</td>\n      <td>...</td>\n      <td>0.335328</td>\n      <td>0.489459</td>\n      <td>0.372010</td>\n      <td>0.666589</td>\n      <td>0.576244</td>\n      <td>0.476087</td>\n      <td>0.585789</td>\n      <td>0.339055</td>\n      <td>0.507992</td>\n      <td>0.294227</td>\n    </tr>\n    <tr>\n      <th>18409</th>\n      <td>2010</td>\n      <td>0.850959</td>\n      <td>0.497077</td>\n      <td>0.513089</td>\n      <td>0.309858</td>\n      <td>0.416551</td>\n      <td>0.252103</td>\n      <td>0.520007</td>\n      <td>0.397299</td>\n      <td>0.462120</td>\n      <td>...</td>\n      <td>0.349319</td>\n      <td>0.480013</td>\n      <td>0.367315</td>\n      <td>0.654323</td>\n      <td>0.583672</td>\n      <td>0.462159</td>\n      <td>0.597104</td>\n      <td>0.350401</td>\n      <td>0.499580</td>\n      <td>0.368927</td>\n    </tr>\n    <tr>\n      <th>18387</th>\n      <td>2010</td>\n      <td>0.744080</td>\n      <td>0.565185</td>\n      <td>0.468783</td>\n      <td>0.371875</td>\n      <td>0.408303</td>\n      <td>0.373937</td>\n      <td>0.542301</td>\n      <td>0.381735</td>\n      <td>0.452571</td>\n      <td>...</td>\n      <td>0.329568</td>\n      <td>0.490258</td>\n      <td>0.389173</td>\n      <td>0.642056</td>\n      <td>0.574659</td>\n      <td>0.492379</td>\n      <td>0.629543</td>\n      <td>0.365311</td>\n      <td>0.498886</td>\n      <td>0.360283</td>\n    </tr>\n    <tr>\n      <th>874</th>\n      <td>2000</td>\n      <td>0.781150</td>\n      <td>0.517066</td>\n      <td>0.447713</td>\n      <td>0.357330</td>\n      <td>0.383889</td>\n      <td>0.243170</td>\n      <td>0.542672</td>\n      <td>0.429323</td>\n      <td>0.482315</td>\n      <td>...</td>\n      <td>0.340546</td>\n      <td>0.495296</td>\n      <td>0.352396</td>\n      <td>0.626926</td>\n      <td>0.571545</td>\n      <td>0.454724</td>\n      <td>0.585541</td>\n      <td>0.344452</td>\n      <td>0.506372</td>\n      <td>0.364665</td>\n    </tr>\n    <tr>\n      <th>20128</th>\n      <td>1950</td>\n      <td>0.742257</td>\n      <td>0.464650</td>\n      <td>0.604671</td>\n      <td>0.335042</td>\n      <td>0.255843</td>\n      <td>0.378839</td>\n      <td>0.405812</td>\n      <td>0.350103</td>\n      <td>0.532451</td>\n      <td>...</td>\n      <td>0.356147</td>\n      <td>0.481544</td>\n      <td>0.376804</td>\n      <td>0.660790</td>\n      <td>0.568658</td>\n      <td>0.460765</td>\n      <td>0.635322</td>\n      <td>0.367661</td>\n      <td>0.507381</td>\n      <td>0.387547</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 91 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(columns=['Unnamed: 0'])\n",
    "#df['label'] = df['label'].astype(str)\n",
    "y = df['label']\n",
    "X = df.drop(columns='label',axis=1)\n",
    "df.sample(5)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from random import randint\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "def split(df,label):\n",
    "    X_tr, X_te, Y_tr, Y_te = train_test_split(df, label, test_size=0.25, random_state=42)\n",
    "    return X_tr, X_te, Y_tr, Y_te\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "\n",
    "\n",
    "classifiers = ['LinearSVM', 'RadialSVM',\n",
    "               'Logistic',  'RandomForest',\n",
    "               'AdaBoost',  'DecisionTree',\n",
    "               'KNeighbors','GradientBoosting']\n",
    "\n",
    "models = [svm.SVC(kernel='linear'),\n",
    "          svm.SVC(kernel='rbf'),\n",
    "          LogisticRegression(max_iter = 1000),\n",
    "          RandomForestClassifier(n_estimators=200, random_state=0),\n",
    "          AdaBoostClassifier(random_state = 0),\n",
    "          DecisionTreeClassifier(random_state=0),\n",
    "          KNeighborsClassifier(),\n",
    "          GradientBoostingClassifier(random_state=0)]\n",
    "def acc_score(df,label):\n",
    "    Score = pd.DataFrame({\"Classifier\":classifiers})\n",
    "    j = 0\n",
    "    acc = []\n",
    "    X_train,X_test,Y_train,Y_test = split(df,label)\n",
    "    for i in models:\n",
    "        model = i\n",
    "        model.fit(X_train,Y_train)\n",
    "        predictions = model.predict(X_test)\n",
    "        acc.append(accuracy_score(Y_test,predictions))\n",
    "        j = j+1\n",
    "    Score[\"Accuracy\"] = acc\n",
    "    Score.sort_values(by=\"Accuracy\", ascending=False,inplace = True)\n",
    "    Score.reset_index(drop=True, inplace=True)\n",
    "    return Score\n",
    "\n",
    "def plot(score,x,y,c = \"b\"):\n",
    "    gen = [1,2,3,4,5]\n",
    "    plt.figure(figsize=(6,4))\n",
    "    ax = sns.pointplot(x=gen, y=score,color = c )\n",
    "    ax.set(xlabel=\"Generation\", ylabel=\"Accuracy\")\n",
    "    ax.set(ylim=(x,y))\n",
    "\n",
    "# Adapted Version\n",
    "def initialization_of_population(size, n_feat):\n",
    "    population = np.random.rand(size, n_feat) < 0.3\n",
    "    temp = np.array([True] * len(population[0]))\n",
    "    population = np.concatenate((population, temp.reshape(1, -1)), axis=0)\n",
    "    return population.astype(np.bool_)\n",
    "\n",
    "def fitness_score(population):\n",
    "    scores = []\n",
    "    for chromosome in population:\n",
    "        logmodel.fit(X_train.iloc[:,chromosome],Y_train)\n",
    "        predictions = logmodel.predict(X_test.iloc[:,chromosome])\n",
    "        score = accuracy_score(Y_test,predictions)\n",
    "        scores.append((score, chromosome))\n",
    "    sorted_array = sorted(scores, key=lambda x: x[0],reverse = True)\n",
    "    sorted_scores, sorted_population = zip(*sorted_array)\n",
    "    return list(sorted_scores), list(sorted_population)\n",
    "\n",
    "def selection(sorted_population,parent_chromosome_number):\n",
    "    next_generation_population = []\n",
    "    for i in range(parent_chromosome_number):\n",
    "        next_generation_population.append(sorted_population[i])\n",
    "    return next_generation_population\n",
    "\n",
    "def crossover(parent_population):\n",
    "    next_generation_population = []\n",
    "    next_generation_population.extend(parent_population)\n",
    "    for i in range(0,len(parent_population),2):\n",
    "        new_chromosome = []\n",
    "        child_1 = parent_population[i]\n",
    "        child_2 = parent_population[i+1]\n",
    "        crossover_point = len(child_1)//2\n",
    "        new_chromosome = np.concatenate((child_1[:crossover_point],child_2[crossover_point:]))\n",
    "        next_generation_population.append(new_chromosome)\n",
    "    return next_generation_population\n",
    "\n",
    "def mutation(population, mutation_rate,n_feat):\n",
    "    next_generation_population = []\n",
    "    mutation_number = int(mutation_rate*n_feat)\n",
    "    for index,chromosome in enumerate(population):\n",
    "        if index == 0:\n",
    "            next_generation_population.append(chromosome)\n",
    "            continue\n",
    "        mutation_position = []\n",
    "        new_chromosome = chromosome.copy()\n",
    "        for i in range(0,mutation_number):\n",
    "            position = randint(0,n_feat-1)\n",
    "            mutation_position.append(position)\n",
    "        for pos in mutation_position:\n",
    "            new_chromosome[pos] = not chromosome[pos]\n",
    "        next_generation_population.append(new_chromosome)\n",
    "    return next_generation_population\n",
    "\n",
    "\n",
    "def generations(df,label,size,n_feat,n_parents,mutation_rate,n_gen,X_train, X_test, Y_train, Y_test):\n",
    "    best_chromo= []\n",
    "    best_score= []\n",
    "    population_nextgen=initialization_of_population(size,n_feat)\n",
    "    for i in range(n_gen):\n",
    "        scores, pop_after_fit = fitness_score(population_nextgen)\n",
    "        print('Best score in generation',i+1,':',scores[0])\n",
    "        pop_after_sel = selection(pop_after_fit,n_parents)\n",
    "        pop_after_cross = crossover(pop_after_sel)\n",
    "        population_nextgen = mutation(pop_after_cross,mutation_rate,n_feat)\n",
    "        best_chromo.append(pop_after_fit[0])\n",
    "        best_score.append(scores[0])\n",
    "    return best_chromo,best_score\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "         Classifier  Accuracy\n0  GradientBoosting  0.419046\n1      RandomForest  0.412783\n2         LinearSVM  0.402100\n3          Logistic  0.401731\n4         RadialSVM  0.395837\n5        KNeighbors  0.380917\n6          AdaBoost  0.338000\n7      DecisionTree  0.258980",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Classifier</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>GradientBoosting</td>\n      <td>0.419046</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>RandomForest</td>\n      <td>0.412783</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>LinearSVM</td>\n      <td>0.402100</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Logistic</td>\n      <td>0.401731</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>RadialSVM</td>\n      <td>0.395837</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>KNeighbors</td>\n      <td>0.380917</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>AdaBoost</td>\n      <td>0.338000</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>DecisionTree</td>\n      <td>0.258980</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score1 = acc_score(X,y)\n",
    "score1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score in generation 1 : 0.4098549389822703\n",
      "Best score in generation 2 : 0.4098549389822703\n",
      "Best score in generation 3 : 0.4098549389822703\n",
      "Best score in generation 4 : 0.4098549389822703\n",
      "Best score in generation 5 : 0.4098549389822703\n",
      "Best score in generation 6 : 0.4098549389822703\n",
      "Best score in generation 7 : 0.4098549389822703\n",
      "Best score in generation 8 : 0.4098549389822703\n",
      "Best score in generation 9 : 0.4098549389822703\n",
      "Best score in generation 10 : 0.4098549389822703\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[9], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m logmodel \u001B[38;5;241m=\u001B[39m GradientBoostingClassifier(random_state\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\n\u001B[1;32m      2\u001B[0m X_train, X_test, Y_train, Y_test \u001B[38;5;241m=\u001B[39m train_test_split(X, y, test_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.2\u001B[39m, random_state\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m42\u001B[39m)\n\u001B[0;32m----> 3\u001B[0m chromo_df_song,score_song\u001B[38;5;241m=\u001B[39m\u001B[43mgenerations\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43msize\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m20\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43mn_feat\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mX\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mshape\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43mn_parents\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m10\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43mmutation_rate\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0.20\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43mn_gen\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m20\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m      4\u001B[0m \u001B[43m                         \u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43mX_test\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mX_test\u001B[49m\u001B[43m,\u001B[49m\u001B[43mY_train\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mY_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43mY_test\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mY_test\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[8], line 121\u001B[0m, in \u001B[0;36mgenerations\u001B[0;34m(df, label, size, n_feat, n_parents, mutation_rate, n_gen, X_train, X_test, Y_train, Y_test)\u001B[0m\n\u001B[1;32m    119\u001B[0m population_nextgen\u001B[38;5;241m=\u001B[39minitialization_of_population(size,n_feat)\n\u001B[1;32m    120\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(n_gen):\n\u001B[0;32m--> 121\u001B[0m     scores, pop_after_fit \u001B[38;5;241m=\u001B[39m \u001B[43mfitness_score\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpopulation_nextgen\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    122\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mBest score in generation\u001B[39m\u001B[38;5;124m'\u001B[39m,i\u001B[38;5;241m+\u001B[39m\u001B[38;5;241m1\u001B[39m,\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m:\u001B[39m\u001B[38;5;124m'\u001B[39m,scores[\u001B[38;5;241m0\u001B[39m])\n\u001B[1;32m    123\u001B[0m     pop_after_sel \u001B[38;5;241m=\u001B[39m selection(pop_after_fit,n_parents)\n",
      "Cell \u001B[0;32mIn[8], line 72\u001B[0m, in \u001B[0;36mfitness_score\u001B[0;34m(population)\u001B[0m\n\u001B[1;32m     70\u001B[0m scores \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m     71\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m chromosome \u001B[38;5;129;01min\u001B[39;00m population:\n\u001B[0;32m---> 72\u001B[0m     \u001B[43mlogmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43miloc\u001B[49m\u001B[43m[\u001B[49m\u001B[43m:\u001B[49m\u001B[43m,\u001B[49m\u001B[43mchromosome\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43mY_train\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     73\u001B[0m     predictions \u001B[38;5;241m=\u001B[39m logmodel\u001B[38;5;241m.\u001B[39mpredict(X_test\u001B[38;5;241m.\u001B[39miloc[:,chromosome])\n\u001B[1;32m     74\u001B[0m     score \u001B[38;5;241m=\u001B[39m accuracy_score(Y_test,predictions)\n",
      "File \u001B[0;32m~/Desktop/cs334 research/venv/lib/python3.10/site-packages/sklearn/ensemble/_gb.py:538\u001B[0m, in \u001B[0;36mBaseGradientBoosting.fit\u001B[0;34m(self, X, y, sample_weight, monitor)\u001B[0m\n\u001B[1;32m    535\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_resize_state()\n\u001B[1;32m    537\u001B[0m \u001B[38;5;66;03m# fit the boosting stages\u001B[39;00m\n\u001B[0;32m--> 538\u001B[0m n_stages \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_fit_stages\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    539\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    540\u001B[0m \u001B[43m    \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    541\u001B[0m \u001B[43m    \u001B[49m\u001B[43mraw_predictions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    542\u001B[0m \u001B[43m    \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    543\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_rng\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    544\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX_val\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    545\u001B[0m \u001B[43m    \u001B[49m\u001B[43my_val\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    546\u001B[0m \u001B[43m    \u001B[49m\u001B[43msample_weight_val\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    547\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbegin_at_stage\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    548\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmonitor\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    549\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    551\u001B[0m \u001B[38;5;66;03m# change shape of arrays after fit (early-stopping or additional ests)\u001B[39;00m\n\u001B[1;32m    552\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m n_stages \u001B[38;5;241m!=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mestimators_\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m]:\n",
      "File \u001B[0;32m~/Desktop/cs334 research/venv/lib/python3.10/site-packages/sklearn/ensemble/_gb.py:615\u001B[0m, in \u001B[0;36mBaseGradientBoosting._fit_stages\u001B[0;34m(self, X, y, raw_predictions, sample_weight, random_state, X_val, y_val, sample_weight_val, begin_at_stage, monitor)\u001B[0m\n\u001B[1;32m    608\u001B[0m     old_oob_score \u001B[38;5;241m=\u001B[39m loss_(\n\u001B[1;32m    609\u001B[0m         y[\u001B[38;5;241m~\u001B[39msample_mask],\n\u001B[1;32m    610\u001B[0m         raw_predictions[\u001B[38;5;241m~\u001B[39msample_mask],\n\u001B[1;32m    611\u001B[0m         sample_weight[\u001B[38;5;241m~\u001B[39msample_mask],\n\u001B[1;32m    612\u001B[0m     )\n\u001B[1;32m    614\u001B[0m \u001B[38;5;66;03m# fit next stage of trees\u001B[39;00m\n\u001B[0;32m--> 615\u001B[0m raw_predictions \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_fit_stage\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    616\u001B[0m \u001B[43m    \u001B[49m\u001B[43mi\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    617\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    618\u001B[0m \u001B[43m    \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    619\u001B[0m \u001B[43m    \u001B[49m\u001B[43mraw_predictions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    620\u001B[0m \u001B[43m    \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    621\u001B[0m \u001B[43m    \u001B[49m\u001B[43msample_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    622\u001B[0m \u001B[43m    \u001B[49m\u001B[43mrandom_state\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    623\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX_csc\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    624\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX_csr\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    625\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    627\u001B[0m \u001B[38;5;66;03m# track deviance (= loss)\u001B[39;00m\n\u001B[1;32m    628\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m do_oob:\n",
      "File \u001B[0;32m~/Desktop/cs334 research/venv/lib/python3.10/site-packages/sklearn/ensemble/_gb.py:257\u001B[0m, in \u001B[0;36mBaseGradientBoosting._fit_stage\u001B[0;34m(self, i, X, y, raw_predictions, sample_weight, sample_mask, random_state, X_csc, X_csr)\u001B[0m\n\u001B[1;32m    254\u001B[0m     sample_weight \u001B[38;5;241m=\u001B[39m sample_weight \u001B[38;5;241m*\u001B[39m sample_mask\u001B[38;5;241m.\u001B[39mastype(np\u001B[38;5;241m.\u001B[39mfloat64)\n\u001B[1;32m    256\u001B[0m X \u001B[38;5;241m=\u001B[39m X_csr \u001B[38;5;28;01mif\u001B[39;00m X_csr \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m X\n\u001B[0;32m--> 257\u001B[0m \u001B[43mtree\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mresidual\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msample_weight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcheck_input\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m    259\u001B[0m \u001B[38;5;66;03m# update tree leaves\u001B[39;00m\n\u001B[1;32m    260\u001B[0m loss\u001B[38;5;241m.\u001B[39mupdate_terminal_regions(\n\u001B[1;32m    261\u001B[0m     tree\u001B[38;5;241m.\u001B[39mtree_,\n\u001B[1;32m    262\u001B[0m     X,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    269\u001B[0m     k\u001B[38;5;241m=\u001B[39mk,\n\u001B[1;32m    270\u001B[0m )\n",
      "File \u001B[0;32m~/Desktop/cs334 research/venv/lib/python3.10/site-packages/sklearn/tree/_classes.py:1247\u001B[0m, in \u001B[0;36mDecisionTreeRegressor.fit\u001B[0;34m(self, X, y, sample_weight, check_input)\u001B[0m\n\u001B[1;32m   1218\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfit\u001B[39m(\u001B[38;5;28mself\u001B[39m, X, y, sample_weight\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, check_input\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m):\n\u001B[1;32m   1219\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Build a decision tree regressor from the training set (X, y).\u001B[39;00m\n\u001B[1;32m   1220\u001B[0m \n\u001B[1;32m   1221\u001B[0m \u001B[38;5;124;03m    Parameters\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1244\u001B[0m \u001B[38;5;124;03m        Fitted estimator.\u001B[39;00m\n\u001B[1;32m   1245\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m-> 1247\u001B[0m     \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1248\u001B[0m \u001B[43m        \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1249\u001B[0m \u001B[43m        \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1250\u001B[0m \u001B[43m        \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msample_weight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1251\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcheck_input\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcheck_input\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1252\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1253\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\n",
      "File \u001B[0;32m~/Desktop/cs334 research/venv/lib/python3.10/site-packages/sklearn/tree/_classes.py:379\u001B[0m, in \u001B[0;36mBaseDecisionTree.fit\u001B[0;34m(self, X, y, sample_weight, check_input)\u001B[0m\n\u001B[1;32m    368\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    369\u001B[0m     builder \u001B[38;5;241m=\u001B[39m BestFirstTreeBuilder(\n\u001B[1;32m    370\u001B[0m         splitter,\n\u001B[1;32m    371\u001B[0m         min_samples_split,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    376\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmin_impurity_decrease,\n\u001B[1;32m    377\u001B[0m     )\n\u001B[0;32m--> 379\u001B[0m \u001B[43mbuilder\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbuild\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtree_\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    381\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_outputs_ \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m is_classifier(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    382\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_classes_ \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_classes_[\u001B[38;5;241m0\u001B[39m]\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "logmodel = GradientBoostingClassifier(random_state=0)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "chromo_df_song,score_song=generations(X,y,size=20,n_feat=X.shape[1],n_parents=10,mutation_rate=0.20,n_gen=20,\n",
    "                         X_train = X_train,X_test = X_test,Y_train = Y_train,Y_test = Y_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
